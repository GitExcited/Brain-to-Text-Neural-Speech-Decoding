{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":106809,"databundleVersionId":13056355,"sourceType":"competition"},{"sourceId":13263160,"sourceType":"datasetVersion","datasetId":8404664}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install omegaconf -q","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-04T19:46:32.102552Z","iopub.execute_input":"2025-10-04T19:46:32.102749Z","iopub.status.idle":"2025-10-04T19:46:36.414990Z","shell.execute_reply.started":"2025-10-04T19:46:32.102732Z","shell.execute_reply":"2025-10-04T19:46:36.413934Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# Copy code files to working directory\n!cp /kaggle/input/rnn-trainer/*.py /kaggle/working/\n!cp /kaggle/input/rnn-trainer/*.yaml /kaggle/working/\n\n# Verify files are there\n!ls -la /kaggle/working/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-04T19:46:36.416068Z","iopub.execute_input":"2025-10-04T19:46:36.416383Z","iopub.status.idle":"2025-10-04T19:46:36.786847Z","shell.execute_reply.started":"2025-10-04T19:46:36.416347Z","shell.execute_reply":"2025-10-04T19:46:36.786015Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"total 84\ndrwxr-xr-x 3 root root  4096 Oct  4 19:46 .\ndrwxr-xr-x 5 root root  4096 Oct  4 19:46 ..\n-rw-r--r-- 1 root root  1744 Oct  4 19:46 data_augmentations.py\n-rw-r--r-- 1 root root 15678 Oct  4 19:46 dataset.py\n-rw-r--r-- 1 root root  6705 Oct  4 19:46 rnn_args.yaml\n-rw-r--r-- 1 root root  5733 Oct  4 19:46 rnn_model.py\n-rw-r--r-- 1 root root 32766 Oct  4 19:46 rnn_trainer.py\n-rw-r--r-- 1 root root   236 Oct  4 19:46 train_model.py\ndrwxr-xr-x 2 root root  4096 Oct  4 19:46 .virtual_documents\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# See where the competition data is\n!ls /kaggle/input/\n!ls /kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final\n!ls /kaggle/input/brain-to-text-25/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-04T19:46:36.788739Z","iopub.execute_input":"2025-10-04T19:46:36.789165Z","iopub.status.idle":"2025-10-04T19:46:37.142149Z","shell.execute_reply.started":"2025-10-04T19:46:36.789130Z","shell.execute_reply":"2025-10-04T19:46:37.141311Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"brain-to-text-25  rnn-trainer\nt15.2023.08.11\tt15.2023.09.29\tt15.2023.11.04\tt15.2024.02.25\tt15.2024.07.19\nt15.2023.08.13\tt15.2023.10.01\tt15.2023.11.17\tt15.2024.03.03\tt15.2024.07.21\nt15.2023.08.18\tt15.2023.10.06\tt15.2023.11.19\tt15.2024.03.08\tt15.2024.07.28\nt15.2023.08.20\tt15.2023.10.08\tt15.2023.11.26\tt15.2024.03.15\tt15.2025.01.10\nt15.2023.08.25\tt15.2023.10.13\tt15.2023.12.03\tt15.2024.03.17\tt15.2025.01.12\nt15.2023.08.27\tt15.2023.10.15\tt15.2023.12.08\tt15.2024.04.25\tt15.2025.03.14\nt15.2023.09.01\tt15.2023.10.20\tt15.2023.12.10\tt15.2024.04.28\tt15.2025.03.16\nt15.2023.09.03\tt15.2023.10.22\tt15.2023.12.17\tt15.2024.05.10\tt15.2025.03.30\nt15.2023.09.24\tt15.2023.11.03\tt15.2023.12.29\tt15.2024.06.14\tt15.2025.04.13\ndata_link.txt  t15_copyTask_neuralData\tt15_pretrained_rnn_baseline\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Check which sessions actually exist in the dataset\nimport os\ndata_path = '/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final'\navailable_sessions = [f.replace('.h5', '') for f in os.listdir(data_path) if\nf.endswith('.h5')]\nprint(\"Available sessions in competition data:\")\nprint(available_sessions)\n\n# Check what's actually there\n!ls -la /kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/\n\n# Also check parent directories\n!ls -la /kaggle/input/brain-to-text-25/t15_copyTask_neuralData/\n!ls -la /kaggle/input/brain-to-text-25/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-04T19:46:37.143411Z","iopub.execute_input":"2025-10-04T19:46:37.143698Z","iopub.status.idle":"2025-10-04T19:46:37.528448Z","shell.execute_reply.started":"2025-10-04T19:46:37.143661Z","shell.execute_reply":"2025-10-04T19:46:37.527531Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Available sessions in competition data:\n[]\ntotal 0\ndrwxr-xr-x 47 nobody nogroup 0 Aug 20 08:09 .\ndrwxr-xr-x  3 nobody nogroup 0 Aug 20 08:09 ..\ndrwxr-xr-x  2 nobody nogroup 0 Aug 20 08:09 t15.2023.08.11\ndrwxr-xr-x  2 nobody nogroup 0 Aug 20 08:09 t15.2023.08.13\ndrwxr-xr-x  2 nobody nogroup 0 Aug 20 08:09 t15.2023.08.18\ndrwxr-xr-x  2 nobody nogroup 0 Aug 20 08:09 t15.2023.08.20\ndrwxr-xr-x  2 nobody nogroup 0 Aug 20 08:09 t15.2023.08.25\ndrwxr-xr-x  2 nobody nogroup 0 Aug 20 08:09 t15.2023.08.27\ndrwxr-xr-x  2 nobody nogroup 0 Aug 20 08:09 t15.2023.09.01\ndrwxr-xr-x  2 nobody nogroup 0 Aug 20 08:09 t15.2023.09.03\ndrwxr-xr-x  2 nobody nogroup 0 Aug 20 08:09 t15.2023.09.24\ndrwxr-xr-x  2 nobody nogroup 0 Aug 20 08:09 t15.2023.09.29\ndrwxr-xr-x  2 nobody nogroup 0 Aug 20 08:09 t15.2023.10.01\ndrwxr-xr-x  2 nobody nogroup 0 Aug 20 08:09 t15.2023.10.06\ndrwxr-xr-x  2 nobody nogroup 0 Aug 20 08:09 t15.2023.10.08\ndrwxr-xr-x  2 nobody nogroup 0 Aug 20 08:09 t15.2023.10.13\ndrwxr-xr-x  2 nobody nogroup 0 Aug 20 08:09 t15.2023.10.15\ndrwxr-xr-x  2 nobody nogroup 0 Aug 20 08:09 t15.2023.10.20\ndrwxr-xr-x  2 nobody nogroup 0 Aug 20 08:09 t15.2023.10.22\ndrwxr-xr-x  2 nobody nogroup 0 Aug 20 08:09 t15.2023.11.03\ndrwxr-xr-x  2 nobody nogroup 0 Aug 20 08:09 t15.2023.11.04\ndrwxr-xr-x  2 nobody nogroup 0 Aug 20 08:09 t15.2023.11.17\ndrwxr-xr-x  2 nobody nogroup 0 Aug 20 08:09 t15.2023.11.19\ndrwxr-xr-x  2 nobody nogroup 0 Aug 20 08:09 t15.2023.11.26\ndrwxr-xr-x  2 nobody nogroup 0 Aug 20 08:09 t15.2023.12.03\ndrwxr-xr-x  2 nobody nogroup 0 Aug 20 08:09 t15.2023.12.08\ndrwxr-xr-x  2 nobody nogroup 0 Aug 20 08:09 t15.2023.12.10\ndrwxr-xr-x  2 nobody nogroup 0 Aug 20 08:09 t15.2023.12.17\ndrwxr-xr-x  2 nobody nogroup 0 Aug 20 08:09 t15.2023.12.29\ndrwxr-xr-x  2 nobody nogroup 0 Aug 20 08:09 t15.2024.02.25\ndrwxr-xr-x  2 nobody nogroup 0 Aug 20 08:09 t15.2024.03.03\ndrwxr-xr-x  2 nobody nogroup 0 Aug 20 08:09 t15.2024.03.08\ndrwxr-xr-x  2 nobody nogroup 0 Aug 20 08:09 t15.2024.03.15\ndrwxr-xr-x  2 nobody nogroup 0 Aug 20 08:09 t15.2024.03.17\ndrwxr-xr-x  2 nobody nogroup 0 Aug 20 08:09 t15.2024.04.25\ndrwxr-xr-x  2 nobody nogroup 0 Aug 20 08:09 t15.2024.04.28\ndrwxr-xr-x  2 nobody nogroup 0 Aug 20 08:09 t15.2024.05.10\ndrwxr-xr-x  2 nobody nogroup 0 Aug 20 08:09 t15.2024.06.14\ndrwxr-xr-x  2 nobody nogroup 0 Aug 20 08:09 t15.2024.07.19\ndrwxr-xr-x  2 nobody nogroup 0 Aug 20 08:09 t15.2024.07.21\ndrwxr-xr-x  2 nobody nogroup 0 Aug 20 08:09 t15.2024.07.28\ndrwxr-xr-x  2 nobody nogroup 0 Aug 20 08:09 t15.2025.01.10\ndrwxr-xr-x  2 nobody nogroup 0 Aug 20 08:09 t15.2025.01.12\ndrwxr-xr-x  2 nobody nogroup 0 Aug 20 08:09 t15.2025.03.14\ndrwxr-xr-x  2 nobody nogroup 0 Aug 20 08:09 t15.2025.03.16\ndrwxr-xr-x  2 nobody nogroup 0 Aug 20 08:09 t15.2025.03.30\ndrwxr-xr-x  2 nobody nogroup 0 Aug 20 08:09 t15.2025.04.13\ntotal 0\ndrwxr-xr-x  3 nobody nogroup 0 Aug 20 08:09 .\ndrwxr-xr-x  4 nobody nogroup 0 Aug 20 08:09 ..\ndrwxr-xr-x 47 nobody nogroup 0 Aug 20 08:09 hdf5_data_final\ntotal 8\ndrwxr-xr-x 4 nobody nogroup    0 Aug 20 08:09 .\ndrwxr-xr-x 4 root   root    4096 Oct  4 19:46 ..\n-rw-r--r-- 1 nobody nogroup   39 Aug 20 08:09 data_link.txt\ndrwxr-xr-x 3 nobody nogroup    0 Aug 20 08:09 t15_copyTask_neuralData\ndrwxr-xr-x 3 nobody nogroup    0 Aug 20 08:09 t15_pretrained_rnn_baseline\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"!ls -la /kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.08.11/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-04T19:46:37.529561Z","iopub.execute_input":"2025-10-04T19:46:37.529836Z","iopub.status.idle":"2025-10-04T19:46:37.652696Z","shell.execute_reply.started":"2025-10-04T19:46:37.529801Z","shell.execute_reply":"2025-10-04T19:46:37.651883Z"}},"outputs":[{"name":"stdout","text":"total 210144\ndrwxr-xr-x  2 nobody nogroup         0 Aug 20 08:09 .\ndrwxr-xr-x 47 nobody nogroup         0 Aug 20 08:09 ..\n-rw-r--r--  1 nobody nogroup 215183394 Aug 20 08:09 data_train.hdf5\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"from omegaconf import OmegaConf\nfrom rnn_trainer import BrainToTextDecoder_Trainer\nimport shutil\nimport os\n\nif __name__ == '__main__':\n  # Clean up any existing trained models in /kaggle/working\n  # Careful when running this to not delete old trained models. Export them first\n  trained_models_path = '/kaggle/working/trained_models'\n  if os.path.exists(trained_models_path):\n      shutil.rmtree(trained_models_path)\n      print(f\"Removed existing trained_models directory:{trained_models_path}\")\n\n  args = OmegaConf.load('rnn_args.yaml')\n  trainer = BrainToTextDecoder_Trainer(args)\n  metrics = trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-04T19:46:37.653794Z","iopub.execute_input":"2025-10-04T19:46:37.654090Z"}},"outputs":[{"name":"stdout","text":"2025-10-04 19:46:45,842: Using device: cuda:1\n2025-10-04 19:46:46,870: Initialized RNN decoding model\n2025-10-04 19:46:46,871: GRUDecoder(\n  (day_layer_activation): Softsign()\n  (day_weights): ParameterList(\n      (0): Parameter containing: [torch.float32 of size 512x512]\n      (1): Parameter containing: [torch.float32 of size 512x512]\n      (2): Parameter containing: [torch.float32 of size 512x512]\n      (3): Parameter containing: [torch.float32 of size 512x512]\n      (4): Parameter containing: [torch.float32 of size 512x512]\n      (5): Parameter containing: [torch.float32 of size 512x512]\n      (6): Parameter containing: [torch.float32 of size 512x512]\n      (7): Parameter containing: [torch.float32 of size 512x512]\n      (8): Parameter containing: [torch.float32 of size 512x512]\n      (9): Parameter containing: [torch.float32 of size 512x512]\n      (10): Parameter containing: [torch.float32 of size 512x512]\n      (11): Parameter containing: [torch.float32 of size 512x512]\n      (12): Parameter containing: [torch.float32 of size 512x512]\n      (13): Parameter containing: [torch.float32 of size 512x512]\n      (14): Parameter containing: [torch.float32 of size 512x512]\n      (15): Parameter containing: [torch.float32 of size 512x512]\n      (16): Parameter containing: [torch.float32 of size 512x512]\n      (17): Parameter containing: [torch.float32 of size 512x512]\n      (18): Parameter containing: [torch.float32 of size 512x512]\n      (19): Parameter containing: [torch.float32 of size 512x512]\n      (20): Parameter containing: [torch.float32 of size 512x512]\n      (21): Parameter containing: [torch.float32 of size 512x512]\n      (22): Parameter containing: [torch.float32 of size 512x512]\n      (23): Parameter containing: [torch.float32 of size 512x512]\n      (24): Parameter containing: [torch.float32 of size 512x512]\n      (25): Parameter containing: [torch.float32 of size 512x512]\n      (26): Parameter containing: [torch.float32 of size 512x512]\n      (27): Parameter containing: [torch.float32 of size 512x512]\n      (28): Parameter containing: [torch.float32 of size 512x512]\n      (29): Parameter containing: [torch.float32 of size 512x512]\n      (30): Parameter containing: [torch.float32 of size 512x512]\n      (31): Parameter containing: [torch.float32 of size 512x512]\n      (32): Parameter containing: [torch.float32 of size 512x512]\n      (33): Parameter containing: [torch.float32 of size 512x512]\n      (34): Parameter containing: [torch.float32 of size 512x512]\n      (35): Parameter containing: [torch.float32 of size 512x512]\n      (36): Parameter containing: [torch.float32 of size 512x512]\n      (37): Parameter containing: [torch.float32 of size 512x512]\n      (38): Parameter containing: [torch.float32 of size 512x512]\n      (39): Parameter containing: [torch.float32 of size 512x512]\n      (40): Parameter containing: [torch.float32 of size 512x512]\n      (41): Parameter containing: [torch.float32 of size 512x512]\n      (42): Parameter containing: [torch.float32 of size 512x512]\n      (43): Parameter containing: [torch.float32 of size 512x512]\n      (44): Parameter containing: [torch.float32 of size 512x512]\n  )\n  (day_biases): ParameterList(\n      (0): Parameter containing: [torch.float32 of size 1x512]\n      (1): Parameter containing: [torch.float32 of size 1x512]\n      (2): Parameter containing: [torch.float32 of size 1x512]\n      (3): Parameter containing: [torch.float32 of size 1x512]\n      (4): Parameter containing: [torch.float32 of size 1x512]\n      (5): Parameter containing: [torch.float32 of size 1x512]\n      (6): Parameter containing: [torch.float32 of size 1x512]\n      (7): Parameter containing: [torch.float32 of size 1x512]\n      (8): Parameter containing: [torch.float32 of size 1x512]\n      (9): Parameter containing: [torch.float32 of size 1x512]\n      (10): Parameter containing: [torch.float32 of size 1x512]\n      (11): Parameter containing: [torch.float32 of size 1x512]\n      (12): Parameter containing: [torch.float32 of size 1x512]\n      (13): Parameter containing: [torch.float32 of size 1x512]\n      (14): Parameter containing: [torch.float32 of size 1x512]\n      (15): Parameter containing: [torch.float32 of size 1x512]\n      (16): Parameter containing: [torch.float32 of size 1x512]\n      (17): Parameter containing: [torch.float32 of size 1x512]\n      (18): Parameter containing: [torch.float32 of size 1x512]\n      (19): Parameter containing: [torch.float32 of size 1x512]\n      (20): Parameter containing: [torch.float32 of size 1x512]\n      (21): Parameter containing: [torch.float32 of size 1x512]\n      (22): Parameter containing: [torch.float32 of size 1x512]\n      (23): Parameter containing: [torch.float32 of size 1x512]\n      (24): Parameter containing: [torch.float32 of size 1x512]\n      (25): Parameter containing: [torch.float32 of size 1x512]\n      (26): Parameter containing: [torch.float32 of size 1x512]\n      (27): Parameter containing: [torch.float32 of size 1x512]\n      (28): Parameter containing: [torch.float32 of size 1x512]\n      (29): Parameter containing: [torch.float32 of size 1x512]\n      (30): Parameter containing: [torch.float32 of size 1x512]\n      (31): Parameter containing: [torch.float32 of size 1x512]\n      (32): Parameter containing: [torch.float32 of size 1x512]\n      (33): Parameter containing: [torch.float32 of size 1x512]\n      (34): Parameter containing: [torch.float32 of size 1x512]\n      (35): Parameter containing: [torch.float32 of size 1x512]\n      (36): Parameter containing: [torch.float32 of size 1x512]\n      (37): Parameter containing: [torch.float32 of size 1x512]\n      (38): Parameter containing: [torch.float32 of size 1x512]\n      (39): Parameter containing: [torch.float32 of size 1x512]\n      (40): Parameter containing: [torch.float32 of size 1x512]\n      (41): Parameter containing: [torch.float32 of size 1x512]\n      (42): Parameter containing: [torch.float32 of size 1x512]\n      (43): Parameter containing: [torch.float32 of size 1x512]\n      (44): Parameter containing: [torch.float32 of size 1x512]\n  )\n  (day_layer_dropout): Dropout(p=0.2, inplace=False)\n  (gru): GRU(7168, 768, num_layers=5, batch_first=True, dropout=0.4)\n  (out): Linear(in_features=768, out_features=41, bias=True)\n)\n2025-10-04 19:46:46,874: Model has 44,315,177 parameters\n2025-10-04 19:46:46,875: Model has 11,819,520 day-specific parameters | 26.67% of total parameters\n2025-10-04 19:47:08,096: Successfully initialized datasets\n2025-10-04 19:47:15,744: Train batch 0: loss: 737.40 grad norm: 302.70 time: 3.847\n2025-10-04 19:47:15,746: Running test after training batch: 0\n2025-10-04 19:47:42,316: Val batch 0: PER (avg): 1.2718 CTC Loss (avg): 711.8865 time: 26.570\n2025-10-04 19:47:42,317: t15.2023.08.13 val PER: 1.1987\n2025-10-04 19:47:42,318: t15.2023.08.18 val PER: 1.3352\n2025-10-04 19:47:42,319: t15.2023.08.20 val PER: 1.2532\n2025-10-04 19:47:42,320: t15.2023.08.25 val PER: 1.1834\n2025-10-04 19:47:42,321: t15.2023.08.27 val PER: 1.1282\n2025-10-04 19:47:42,321: t15.2023.09.01 val PER: 1.2440\n2025-10-04 19:47:42,322: t15.2023.09.03 val PER: 1.1273\n2025-10-04 19:47:42,323: t15.2023.09.24 val PER: 1.3799\n2025-10-04 19:47:42,323: t15.2023.09.29 val PER: 1.1288\n2025-10-04 19:47:42,324: t15.2023.10.01 val PER: 1.1484\n2025-10-04 19:47:42,325: t15.2023.10.06 val PER: 1.4960\n2025-10-04 19:47:42,327: t15.2023.10.08 val PER: 1.2603\n2025-10-04 19:47:42,328: t15.2023.10.13 val PER: 1.1897\n2025-10-04 19:47:42,328: t15.2023.10.15 val PER: 1.2319\n2025-10-04 19:47:42,329: t15.2023.10.20 val PER: 1.1592\n2025-10-04 19:47:42,330: t15.2023.10.22 val PER: 1.3433\n2025-10-04 19:47:42,331: t15.2023.11.03 val PER: 1.6811\n2025-10-04 19:47:42,332: t15.2023.11.04 val PER: 1.6188\n2025-10-04 19:47:42,333: t15.2023.11.17 val PER: 1.8038\n2025-10-04 19:47:42,334: t15.2023.11.19 val PER: 1.4242\n2025-10-04 19:47:42,334: t15.2023.11.26 val PER: 1.3263\n2025-10-04 19:47:42,335: t15.2023.12.03 val PER: 1.2843\n2025-10-04 19:47:42,336: t15.2023.12.08 val PER: 1.2756\n2025-10-04 19:47:42,337: t15.2023.12.10 val PER: 1.4655\n2025-10-04 19:47:42,338: t15.2023.12.17 val PER: 1.2869\n2025-10-04 19:47:42,338: t15.2023.12.29 val PER: 1.2158\n2025-10-04 19:47:42,339: t15.2024.02.25 val PER: 1.0926\n2025-10-04 19:47:42,340: t15.2024.03.08 val PER: 1.1016\n2025-10-04 19:47:42,341: t15.2024.03.15 val PER: 1.3133\n2025-10-04 19:47:42,341: t15.2024.03.17 val PER: 1.2016\n2025-10-04 19:47:42,342: t15.2024.05.10 val PER: 1.4811\n2025-10-04 19:47:42,343: t15.2024.06.14 val PER: 1.4229\n2025-10-04 19:47:42,343: t15.2024.07.19 val PER: 0.9868\n2025-10-04 19:47:42,344: t15.2024.07.21 val PER: 1.5393\n2025-10-04 19:47:42,346: t15.2024.07.28 val PER: 1.4022\n2025-10-04 19:47:42,347: t15.2025.01.10 val PER: 1.0498\n2025-10-04 19:47:42,347: t15.2025.01.12 val PER: 1.4530\n2025-10-04 19:47:42,348: t15.2025.03.14 val PER: 1.0309\n2025-10-04 19:47:42,349: t15.2025.03.16 val PER: 1.4762\n2025-10-04 19:47:42,349: t15.2025.03.30 val PER: 1.1290\n2025-10-04 19:47:42,350: t15.2025.04.13 val PER: 1.1476\n2025-10-04 19:47:42,351: New best test PER inf --> 1.2718\n2025-10-04 19:47:42,351: Checkpointing model\n2025-10-04 19:47:43,126: Saved model to checkpoint: /kaggle/working/my_trained_model/checkpoint/best_checkpoint\n2025-10-04 19:49:49,792: Train batch 200: loss: 86.00 grad norm: 39.66 time: 0.602\n2025-10-04 19:51:59,252: Train batch 400: loss: 81.69 grad norm: 54.96 time: 0.853\n2025-10-04 19:54:09,219: Train batch 600: loss: 51.60 grad norm: 40.74 time: 0.615\n","output_type":"stream"}],"execution_count":null}]}