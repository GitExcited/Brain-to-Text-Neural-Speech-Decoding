% Course Project Proposal built on the CVPR 2026 Author Kit
% Repo expects: src/cvpr.sty, src/ieeenat_fullname.bst, src/preamble.tex

\documentclass[10pt,twocolumn,letterpaper]{article}

% REVIEW build (per assignment). For camera-ready, switch to \usepackage{cvpr}.
\usepackage[review]{cvpr}
% \usepackage{cvpr}


% CVPR preamble (loads amsmath, amssymb, graphicx, xcolor, etc.)
\input{preamble}

% Hyperlinks (recommended for review)
\definecolor{cvprblue}{rgb}{0.21,0.49,0.74}
\usepackage[pagebackref,breaklinks,colorlinks,allcolors=cvprblue]{hyperref}

% Paper meta (adapted for course)
\def\paperID{0000}
\def\confName{COMP433/6331}
\def\confYear{2025}

\title{Course Project Proposal: Brain-to-Text '25 Kaggle Challenge}

\author{
Course: COMP 433 -- Fall 2025 \\
Members: \\
J. David Ruiz (40176885) \\
Elion Abdyli (40132982) \\
Ion Turcan (40154098) \\
Kirill Vishnyakov (40281175) \\
\\
Concordia University
}
\begin{document}
\maketitle
\thispagestyle{empty}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Proposal content
%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Problem Statement and Application}
We are investigating the problem of linguistic neural decoding for communication restoration in individuals who have lost speech ability, for example due to stroke or ALS.  
This project is based on the \textbf{Brain-to-Text '25 Kaggle Challenge}, which provides EEG recordings of participants listening to spoken sentences and requires models to decode these into text.  

The problem is important because the ability to restore speech would drastically improve quality of life for patients suffering from severe communication impairments.  
Challenges include reproducing an end-to-end pipeline on EEG data, handling complex input formats, ensuring reproducibility of baselines, and understanding how model components contribute to performance.  
Our expectation is to first reproduce working benchmarks and then explore improvements.  
Possible improvement strategies include data augmentation, architectural changes such as switching from RNNs to Transformer variants, experimenting with loss functions, and investigating different tokenization approaches.  
Throughout, we will document reproducibility issues, bottlenecks, and both successful and unsuccessful attempts.  

\section{Reading Material}
We selected four main references that ground our understanding of the problem:  

\textbf{EEG$\to$Speech with auxiliary phoneme prediction:} \cite{lee_enhancing_2025}.  
This paper trains an EEG encoder--decoder to compress EEG into latent features and reconstruct signals.  
A phoneme predictor then outputs phoneme probabilities from the latent space, forming a self-supervised constraint on EEG representations.  
While their model also uses a speech module not directly applicable to our dataset, it is highly relevant to our setup.  

\textbf{Deep learning architectures for speech recognition:} \cite{papastratis_speech_2021}.  
This review surveys RNNs, CTC-based models, and seq2seq approaches.  
It contextualizes why the Kaggle baseline model uses causal RNNs and CTC, and compares architectures for performance and trade-offs.  

\textbf{Transformer for EEG decoding:} \cite{lee_eeg-transformer_2021}.  
This study shows how Transformer-based architectures can outperform RNNs for EEG sequence modeling, suggesting a promising improvement direction.  

\textbf{Host teamâ€™s neuroprosthesis baseline:} \cite{card_accurate_2024}.  
This paper, from the competition organizers, outlines their ensemble causal RNN with 5-gram language modeling.  
It provides critical context for the baseline, evaluation, and neuroprosthesis motivation.  

\section{Possible Methodology}
Our methodology involves structured steps to reproduce and extend results:  

\textbf{Technical process:}
\begin{itemize}
    \item \textbf{Run existing benchmarks:} load provided Kaggle baselines without training and verify inference.  
    These include Stanford-NPTL causal RNN ensemble (with TTA+5-gram) and UCD-NPL causal RNN (+5-gram).  
    If missing, implement a submission script for Kaggle output.  
    \item \textbf{Simple baselines:} implement fast-to-train models such as random, mean, median, linear regression, logistic regression, kNN, and SVM.  
    \item \textbf{Improvement strategies:} 
    \begin{itemize}
        \item Hyperparameter search  
        \item Data preprocessing and augmentation  
        \item Loss function alternatives  
        \item Alternative architectures (GRU, Transformer)  
    \end{itemize}
    \item \textbf{Repository workflow:} clone Kaggle baselines into our repo for version control, track modifications, and swap components such as optimizers or tokenizers.  
    \item \textbf{Kaggle operations:} submit a dummy CSV (done), submit loaded baseline predictions, then trained models for leaderboard evaluation.  
\end{itemize}

\section{Metric Evaluation}
The primary evaluation metric is \emph{word error rate} (WER), computed as edit distance at the word level (substitutions, insertions, deletions).  
The official deliverable is a CSV file containing predictions for 1,450 test sentences.  

During training, we will track loss and visualize learning curves.  
For model comparison, we will use WER across baselines and improvements, report leaderboard performance, and qualitatively analyze example outputs.  
Plots of loss trajectories and WER trends over time will be included in the final report.  

{\small
\nocite{*}
\bibliographystyle{ieeenat_fullname}
\bibliography{src/references}
}

\clearpage
\appendix
\section*{Supplement: Gantt Chart}
\begin{table}[h!]
\centering
\scriptsize
\renewcommand{\arraystretch}{1.2}
\resizebox{\textwidth}{!}{%
\begin{tabular}{|p{2.6cm}|p{4.2cm}|p{2.4cm}|*{8}{c|}|p{3.8cm}|}
\hline
\textbf{Phase / Task} & \textbf{Description} & \textbf{Responsible} & W1 & W2 & W3 & W4 & W5 & W6 & W7 & W8 & \textbf{Milestone} \\
\hline
Project Setup & Choose competition, scope, roles & All & \checkmark &  &  &  &  &  &  &  & Selected competition \\
Proposal Draft & Write and format proposal & All (Lead: Ion) & \checkmark & \checkmark &  &  &  &  &  &  & Submission-ready draft \\
Literature Review & Collect and summarize key papers & Kirill &  & \checkmark & \checkmark & \checkmark &  &  &  &  & Curated reading list \\
Environment Setup & Kaggle/Colab/Codespaces; clone baselines & David &  & \checkmark & \checkmark &  &  &  &  &  & Reproducible env \\
Benchmark Exploration & Run/analyze baseline models & All &  &  & \checkmark & \checkmark &  &  &  &  & Initial submission \\
Baseline Validation & Train/validate baselines & Elion \& Ion &  &  &  & \checkmark & \checkmark &  &  &  & Leaderboard score \\
Model Improvement & Arch changes, tuning, losses & All &  &  &  &  & \checkmark & \checkmark & \checkmark &  & Improved model \\
Evaluation & WER and qualitative outputs & Kirill \& David &  &  &  &  &  & \checkmark & \checkmark &  & Eval report \\
Final Report & Paper \& slides & Elion \& Ion &  &  &  &  &  &  & \checkmark & \checkmark & Final submission \\
\hline
\end{tabular}%
}
\end{table}

\end{document}
